/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 07.11.2022 20:09:25

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 4464;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[23];
TfLiteEvalTensor tflEvalTensors[23];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[11];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,650 } };
const TfArray<1, float> quant0_scale = { 1, { 0.050557747483253479, } };
const TfArray<1, int> quant0_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 50, 13, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 50, 1, 32, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 25, 32, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 25, 1, 16, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data5[2] = { -1, 208, };
const TfArray<1, int> tensor_dimension5 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data6[32*1*3*13] = { 
  /* [0][0][][] */ 127,119,-15,-3,59,27,-9,6,-1,-12,11,-25,-2, -85,45,1,-22,-5,6,-6,-5,-6,-25,4,-1,6, -53,-78,-42,25,8,-19,-4,24,-5,6,4,-21,-8, 
  /* [1][0][][] */ -127,-44,42,12,-81,1,31,0,-3,-5,-17,8,8, -78,22,12,6,-13,14,-8,2,3,4,17,2,5, -81,24,86,44,10,25,-20,6,9,4,-12,-4,-3, 
  /* [2][0][][] */ 127,-15,5,-10,-10,-4,4,-9,6,10,-4,-1,0, -21,-7,-6,3,-4,2,-1,-6,-5,9,1,-2,0, -96,-12,-17,10,2,-1,4,0,6,-3,2,-3,-8, 
  /* [3][0][][] */ -102,106,8,-45,35,70,33,-36,24,4,2,-34,13, -105,-17,-59,2,71,-18,-8,37,7,-4,-12,12,-7, -75,-127,-68,58,3,-38,29,4,-18,49,-34,8,-13, 
  /* [4][0][][] */ -48,-4,-60,24,15,-48,8,28,-18,-22,3,28,-14, 31,26,-45,61,-19,-37,27,29,-38,5,28,-16,10, 42,5,-31,58,-127,11,-8,-6,4,15,-3,15,16, 
  /* [5][0][][] */ 127,-85,-26,-74,27,9,83,8,62,-34,-7,21,-7, 69,22,-104,-34,-63,18,73,33,11,17,-65,-5,6, 95,-93,-73,-42,0,-2,60,-21,-19,16,23,25,13, 
  /* [6][0][][] */ -93,-65,-110,57,-12,10,-37,36,19,-33,42,-24,7, -36,14,-104,-36,34,32,-23,-18,-45,-34,72,19,-20, 106,60,-127,-28,96,9,6,-44,55,-31,14,-9,20, 
  /* [7][0][][] */ 70,100,-76,-127,24,1,-7,-8,31,-6,0,-10,41, -11,37,-36,-33,30,-5,-18,6,27,16,-25,3,-11, -64,5,-1,-66,61,-24,-37,2,-21,35,-22,8,0, 
  /* [8][0][][] */ -115,-33,-11,-19,3,-8,-8,-13,3,0,-4,-11,4, -4,-74,12,-26,28,13,13,-1,-9,9,7,-11,11, -20,127,16,42,-33,0,-14,10,-32,-3,-19,-8,-6, 
  /* [9][0][][] */ 1,88,-16,23,7,25,8,0,-2,6,1,2,17, -12,127,-2,39,-12,38,-5,-1,-15,27,-7,-16,-5, -4,58,51,42,46,11,13,-4,17,-12,22,-6,1, 
  /* [10][0][][] */ -107,-85,18,13,23,-14,9,4,7,1,9,-9,-7, -12,44,-17,-7,-4,-12,11,-2,2,3,-10,0,-2, 127,15,-14,-4,-23,5,-2,7,-6,1,-1,-14,3, 
  /* [11][0][][] */ -74,-52,85,-40,1,-18,5,-4,-6,12,-12,16,5, 105,6,98,-23,-3,9,-24,28,13,-24,-8,-20,5, -127,-75,103,-25,-45,27,-11,5,3,18,5,12,-9, 
  /* [12][0][][] */ -77,18,6,-6,-1,-26,-24,5,-2,12,-3,20,-5, 51,-95,-38,59,-50,-13,-17,11,-2,-7,14,20,-5, -42,-127,7,25,-2,-27,2,2,-15,29,0,-2,-8, 
  /* [13][0][][] */ 63,26,-81,-40,-18,28,19,13,2,-11,-3,-16,20, 49,15,-75,-13,-13,6,22,29,-11,-32,-1,-43,21, 127,37,-95,13,-35,10,15,8,-13,39,-18,28,11, 
  /* [14][0][][] */ 37,-19,-2,1,52,-4,19,-8,24,9,-2,-16,-6, -127,-26,-6,0,-7,10,-6,6,-7,8,-7,-5,-2, -17,-3,-35,-32,-38,-4,14,-2,-8,-3,-2,1,6, 
  /* [15][0][][] */ -101,61,47,-53,-50,54,35,-41,-21,-22,21,22,-35, 19,127,39,-35,-34,79,0,-40,35,18,15,-37,-60, 13,34,-53,-72,19,22,-48,-48,51,22,-19,-29,25, 
  /* [16][0][][] */ 127,17,39,1,-20,-13,-23,-5,-3,-4,1,8,4, -23,-1,15,3,-12,8,-3,-6,3,-12,6,16,11, -115,-58,40,25,0,0,-11,-10,2,-13,7,7,-11, 
  /* [17][0][][] */ 33,66,-58,64,5,12,0,33,-13,11,3,-25,-11, -127,26,0,40,22,17,29,18,-15,13,34,-28,6, 26,-83,119,-80,78,-6,35,-19,54,-27,3,18,-10, 
  /* [18][0][][] */ 55,-127,-13,-33,58,-10,12,-20,20,4,-23,10,-9, -47,34,-2,13,-43,-7,-3,0,-20,23,-2,-11,5, 48,74,15,0,-51,-22,-24,7,-23,3,6,-13,0, 
  /* [19][0][][] */ -103,70,14,76,-10,109,-47,-21,2,9,15,-14,-24, -54,105,56,49,58,-11,7,-15,2,36,6,-5,6, 2,19,127,15,26,26,-3,6,8,-16,-17,15,-11, 
  /* [20][0][][] */ -127,66,-16,9,-2,11,11,11,4,-14,8,11,-4, 2,-88,4,-22,32,-23,16,-28,10,-2,-5,-5,-6, 98,-41,-15,9,-27,-16,-21,1,3,10,-1,-2,-6, 
  /* [21][0][][] */ 127,49,-16,-19,2,-71,12,44,-60,-8,-6,-5,-5, -25,72,-28,16,-7,-114,0,18,-83,11,4,16,28, 33,44,62,-44,78,-102,16,3,-3,31,-5,25,-11, 
  /* [22][0][][] */ -23,72,14,48,-70,12,-33,7,-1,-11,-5,-24,4, 31,-78,76,-25,12,12,-39,23,-20,15,20,5,0, 90,-127,124,-55,15,26,-41,2,-18,-20,-4,1,-27, 
  /* [23][0][][] */ 105,-25,12,10,52,-39,4,-9,33,-11,11,15,13, 91,-81,11,13,47,-31,9,-5,0,4,-6,-21,-8, -44,-127,-4,12,44,-42,-11,-15,12,12,24,7,-15, 
  /* [24][0][][] */ 127,40,121,-74,-25,84,-77,58,-5,40,25,18,-1, 74,105,63,-97,23,71,-31,48,-32,13,-31,24,19, 69,118,59,-35,36,8,-44,20,-8,7,37,66,-4, 
  /* [25][0][][] */ -66,8,-49,-39,-124,-22,32,73,7,-41,-19,4,-31, 94,-61,23,-38,-17,-29,33,43,16,-50,-24,11,30, -82,39,-94,-79,-127,30,39,42,-6,-28,0,4,18, 
  /* [26][0][][] */ 102,9,80,2,-30,6,18,-40,19,-23,-18,6,-26, 120,-9,-2,7,32,27,32,-86,46,-46,19,-27,-21, 127,-6,38,30,88,14,3,-80,42,-66,17,-70,-26, 
  /* [27][0][][] */ 127,-101,71,-105,-42,-4,-30,-4,26,-29,-15,18,-3, 19,48,1,14,-113,24,20,-18,25,-21,-18,13,24, -15,86,-36,48,-106,20,32,-3,7,6,0,-2,36, 
  /* [28][0][][] */ -127,-16,-33,53,43,-19,50,-32,29,-29,-19,30,-12, 40,-39,62,23,-41,42,-16,13,27,6,-11,28,-1, 76,27,60,25,-45,53,-42,-13,22,-32,31,5,-17, 
  /* [29][0][][] */ -18,-121,-3,26,42,-49,-1,-25,11,-20,-19,-6,-14, 16,-32,6,9,17,-42,10,21,13,3,24,4,19, -127,-96,7,8,15,-1,4,-7,-2,20,10,2,6, 
  /* [30][0][][] */ 12,-59,127,51,-2,-13,13,-80,23,-14,-21,21,-14, 108,38,78,-12,-35,-53,-39,-38,-21,-9,3,35,28, 81,25,66,7,-50,-78,-17,-7,-17,27,9,4,47, 
  /* [31][0][][] */ 82,127,112,51,42,-17,27,26,-4,10,5,14,-13, -62,-127,-56,-32,-22,5,13,12,-3,-5,-3,-6,-17, 13,33,-34,-11,3,-6,18,-6,-1,6,10,3,22, 
};
const TfArray<4, int> tensor_dimension6 = { 4, { 32,1,3,13 } };
const TfArray<32, float> quant6_scale = { 32, { 0.013662496581673622, 0.0095019470900297165, 0.020545773208141327, 0.0077518303878605366, 0.010313544422388077, 0.0047648763284087181, 0.0060144839808344841, 0.0085128787904977798, 0.010731455869972706, 0.0088597293943166733, 0.015874553471803665, 0.0087452484294772148, 0.01283686887472868, 0.0069745499640703201, 0.015146919526159763, 0.0081527791917324066, 0.017352322116494179, 0.0087529951706528664, 0.013450576923787594, 0.0063645592890679836, 0.010673188604414463, 0.0067079290747642517, 0.0082618072628974915, 0.0083793094381690025, 0.0051160217262804508, 0.0078101139515638351, 0.0064648920670151711, 0.006314063910394907, 0.0077628619037568569, 0.0095639405772089958, 0.0065909931436181068, 0.013772872276604176, } };
const TfArray<32, int> quant6_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int32_t tensor_data7[32] = { -5192, -4421, -2212, -7891, -6952, -5083, -10196, -9850, -2540, -6338, -3249, -4472, -4881, -7500, -1219, -10035, -3445, -5497, -5495, -6081, -3337, -8901, -7853, -3852, -12898, -7070, -9736, -5767, -6371, -3851, -7106, -4995, };
const TfArray<1, int> tensor_dimension7 = { 1, { 32 } };
const TfArray<32, float> quant7_scale = { 32, { 0.00069074507337063551, 0.0004803970514331013, 0.0010387479560449719, 0.00039191509131342173, 0.00052142958156764507, 0.00024090141232591122, 0.00030407877056859434, 0.00043039198499172926, 0.00054255826398730278, 0.00044792797416448593, 0.00080258166417479515, 0.00044214006629772484, 0.00064900319557636976, 0.00035261752782389522, 0.00076579413143917918, 0.0004121861420571804, 0.0008772943401709199, 0.00044253171654418111, 0.00068003084743395448, 0.00032177777029573917, 0.00053961237426847219, 0.00033913779770955443, 0.00041769837844185531, 0.00042363902321085334, 0.00025865453062579036, 0.00039486176683567464, 0.00032685039332136512, 0.00031922484049573541, 0.00039247280801646411, 0.00048353130114264786, 0.00033322576200589538, 0.00069632538361474872, } };
const TfArray<32, int> quant7_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int8_t tensor_data8[16*1*3*32] = { 
  /* [0][0][][] */ -26,-21,12,-7,-3,10,-7,-27,-24,2,-9,-127,-72,0,-13,-28,-20,11,-23,-7,-34,-3,-15,-6,-58,-12,9,0,-3,-65,-2,-16, -29,-15,-3,-23,-1,-7,-3,-13,-14,-1,-35,-5,-9,-5,-13,-6,-31,9,-1,2,-4,-5,-1,-16,-15,-27,4,-11,-4,-25,2,-18, -7,-8,-28,-5,1,-31,-8,11,-11,5,-20,13,-30,-12,-34,0,-4,-2,7,7,-26,8,-1,-21,7,-12,2,-3,1,-112,2,-54, 
  /* [1][0][][] */ 15,5,-20,-7,13,-26,4,-5,9,0,-12,20,-6,-49,1,31,-17,-31,-18,1,-12,-25,-54,-17,-111,7,-94,-51,-20,-10,-38,42, 2,-2,-35,-7,11,-45,-3,-4,-4,-19,-20,16,-19,-65,3,23,-22,-29,-55,-4,-20,-26,-66,-35,-91,5,-112,-53,-30,-11,-49,6, 13,10,13,-25,56,-30,-25,5,6,-37,-17,12,-23,-9,-9,33,-16,-34,-28,-11,-14,-7,-76,-28,-127,15,-77,-46,-23,-12,-12,28, 
  /* [2][0][][] */ 5,1,-12,3,9,-18,0,-19,2,-3,5,-1,4,-31,1,-19,-3,2,-1,1,0,-13,5,-4,2,-11,4,-10,4,1,0,-3, -18,-2,-10,1,10,-24,-5,-11,0,-4,1,-2,-1,-8,-1,-6,0,-5,-1,0,-2,-2,4,-5,-1,-7,1,-2,2,2,-1,-12, -13,-2,-6,-82,9,-23,-127,-11,-4,-2,-5,0,-16,-17,-15,-11,2,-3,-5,0,-3,1,3,-7,5,-9,8,2,4,-22,2,-7, 
  /* [3][0][][] */ -21,-17,-15,-25,-23,-6,23,-7,-21,-3,-2,17,30,3,-11,-5,-9,-5,-12,8,-5,-48,7,-20,2,-11,3,3,22,-15,2,-15, -16,-12,3,-19,-17,6,10,-6,-32,1,-19,9,-9,0,-10,-4,-22,-51,-25,-12,7,-60,-15,-15,-2,2,-5,10,5,-22,5,-8, -13,-36,4,-30,13,8,23,-17,-31,7,-14,-117,-50,4,1,-9,-41,1,1,-17,-2,-5,-127,-4,-24,11,-13,9,-9,-30,-4,-15, 
  /* [4][0][][] */ -4,-61,18,-27,16,19,-28,10,-27,-53,32,-49,-29,11,-8,-19,-1,12,-22,-127,3,6,-33,-23,-8,-5,-57,9,-52,-56,-35,-21, -65,-18,5,-33,5,5,-29,-32,-29,-30,3,20,2,-4,-14,-47,0,9,11,-54,20,3,-25,-22,-34,10,-39,11,-9,-34,-23,13, -25,9,25,-22,-26,-14,-65,-62,22,-2,9,18,-4,-30,-2,-14,33,13,-8,-7,14,9,2,-2,-27,-2,-49,24,27,-12,-23,-10, 
  /* [5][0][][] */ 2,3,-15,-10,-6,-6,2,12,2,10,-22,-10,-2,2,-20,1,-19,12,5,4,7,10,-2,-11,-7,-1,-17,-9,7,-38,-7,-1, -4,-10,-4,-13,-52,2,-9,0,-24,-2,-3,-8,-18,-13,-26,2,-10,7,-26,8,4,4,-5,5,-4,-3,-4,-25,-3,-2,-11,0, -1,-13,0,-19,-127,0,4,-10,-28,-9,-23,-1,-13,-13,-2,-2,-4,3,-44,-7,0,-10,-4,4,-24,-16,3,-40,-9,0,-11,1, 
  /* [6][0][][] */ 9,-47,9,1,-2,-1,11,7,-12,0,-3,-114,-9,4,3,2,-21,2,-16,-36,-3,-3,-117,-27,-2,4,-38,1,-59,-10,-127,-8, 3,-15,6,2,-1,1,0,-1,-11,-6,0,-59,2,-3,0,5,-23,3,-12,-26,10,-13,-16,0,0,-1,-28,0,-16,-7,-32,-3, 9,-61,0,2,0,8,3,0,-17,-15,-1,-33,2,-10,-1,0,-16,-6,-21,-57,5,-20,-42,3,-78,2,-6,-25,-15,2,-59,-11, 
  /* [7][0][][] */ -7,-13,8,-7,-127,7,-27,-18,-46,-28,-39,-1,-24,-13,-3,-15,7,-20,-33,-38,-22,-9,-10,10,9,-11,9,-34,-12,0,-2,0, 5,-8,9,3,-19,-4,1,-20,8,2,1,-9,-11,-95,4,-105,1,8,-44,-8,12,-16,-35,-5,-14,-4,-34,-71,13,1,-108,-8, -23,-8,-25,3,1,5,-17,-67,11,-7,6,-2,-6,-9,-3,-9,-89,0,5,-10,5,-17,-3,-8,-4,1,1,17,8,-4,-5,-12, 
  /* [8][0][][] */ 7,-33,-22,-19,-4,5,5,7,-1,0,3,-27,-2,6,7,9,-78,0,3,-44,-8,1,-8,6,11,-9,5,0,-2,-13,-5,0, -8,-41,-22,-44,-4,0,-4,1,-90,5,-36,-27,-6,-1,-55,14,-45,-21,-6,-49,-23,0,-6,-1,-1,0,5,-1,-49,0,-10,-19, -6,-25,-10,-127,16,6,-5,0,-26,-2,-63,-9,-4,-1,-25,3,-17,-1,5,-19,-38,17,-9,-1,8,-4,1,2,-7,-3,-2,-17, 
  /* [9][0][][] */ -5,2,-62,-69,8,7,1,-7,-28,22,-15,2,-14,7,-95,1,1,-59,-4,-1,-32,22,2,-1,6,18,3,9,-14,-62,16,2, -9,-8,-15,-6,10,-3,15,-7,-57,2,-59,3,-9,-11,-108,-7,4,-55,0,-10,-63,-2,-4,-4,3,-3,5,6,-2,-33,-5,-10, -10,22,0,-17,14,11,2,4,1,2,-127,8,-35,24,-8,13,13,-15,-13,8,-53,-4,6,-9,6,3,-1,22,12,-51,1,-22, 
  /* [10][0][][] */ 4,-11,3,-81,17,11,-22,-55,-11,12,3,-34,-99,-4,-47,6,-47,-3,-13,7,-34,-4,-37,-22,12,-17,26,6,-1,-127,-21,-43, 21,4,-9,-2,-11,-43,-22,-56,-19,9,-28,-40,-1,-29,-6,-5,1,-2,-54,4,7,1,-40,-54,-6,-8,3,-11,-14,-31,-17,8, 24,2,-15,14,22,-19,-9,-47,-11,-12,4,3,17,-50,8,7,-6,-1,4,3,8,3,26,4,-65,-18,-97,-48,-9,-3,-57,3, 
  /* [11][0][][] */ -14,13,-89,0,-4,-119,-53,-32,2,-2,-14,0,-4,-78,-18,-1,-16,-5,-4,18,-1,-3,1,-66,-2,-32,-6,1,7,-27,1,4, -23,3,-42,-19,-11,-1,-6,-1,0,2,-15,-4,-9,-4,-15,0,-9,-11,-11,-4,-16,4,-7,-31,-4,-4,-4,-5,3,-10,3,10, -15,-46,-33,-44,-21,9,9,7,-32,-15,-5,4,-112,4,-20,6,-64,-6,-31,-8,-39,6,-11,-46,0,9,-31,1,-21,-127,0,10, 
  /* [12][0][][] */ -28,-23,0,-15,-4,6,-1,-15,-1,-12,6,-20,4,-16,-8,-4,-17,-28,16,-60,-9,9,-33,9,-20,-11,-8,5,-6,1,8,-10, -6,-9,-8,-127,-9,-9,-22,-8,-4,1,5,-14,-9,-13,-8,3,-5,3,13,-9,-10,7,-14,-7,-4,-31,-4,6,4,-5,8,-16, -1,1,-14,-20,-10,-42,-46,-17,1,5,5,-5,-34,-47,-25,-12,-4,15,30,8,-2,12,5,0,-6,-94,6,-13,-8,-23,3,-12, 
  /* [13][0][][] */ -4,-2,3,-17,-5,-15,-127,-5,-1,-30,0,4,-8,-12,-5,-12,6,-31,5,0,11,-4,-5,-13,6,-10,1,2,6,-8,2,-3, -9,2,1,1,-1,-19,-7,7,-6,-27,2,2,4,-53,-1,-7,4,-3,-40,-1,3,-15,-5,-7,-2,-10,-3,-2,-3,-4,-1,0, -1,-2,-8,3,3,-3,0,1,-2,-54,0,-1,6,-33,0,11,-1,-1,1,-11,2,-2,2,5,-23,-10,-5,-14,-2,1,-5,-1, 
  /* [14][0][][] */ -31,17,-31,-23,-16,-67,-10,-49,3,2,2,8,-28,-127,-3,9,-8,-6,-35,7,-7,-10,-5,-47,14,-12,3,-1,22,-37,-14,-22, 5,0,-46,-14,0,-13,3,-8,9,2,-48,-33,-55,-24,-22,9,-49,-14,-18,-1,-74,-6,-25,-125,5,-38,15,4,12,-76,-21,-2, 18,-22,0,7,-4,-15,32,11,-14,4,-93,-77,8,-12,-7,19,-3,-15,-53,-1,-11,-8,-59,-34,1,-10,-12,-19,-23,-16,-69,1, 
  /* [15][0][][] */ 6,-14,3,0,-17,-5,16,53,-8,-54,0,-33,12,8,3,42,-5,-5,3,-62,4,1,-45,-12,1,-19,-61,-44,-36,-1,12,0, 14,-48,3,2,-15,2,3,-23,-16,-62,16,-44,1,-1,3,8,3,-40,-15,-127,-7,13,-98,-3,13,-3,-9,-13,-49,-4,-22,-8, 15,-52,0,-6,-11,3,13,37,-43,-48,12,-46,5,6,-4,50,-8,-18,-10,-70,10,0,-42,27,28,-11,8,-26,-58,4,-59,-27, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 16,1,3,32 } };
const TfArray<16, float> quant8_scale = { 16, { 0.028489915654063225, 0.011236547492444515, 0.044389314949512482, 0.019923480227589607, 0.01013129111379385, 0.032698579132556915, 0.036110866814851761, 0.022311225533485413, 0.033123612403869629, 0.019192267209291458, 0.015776239335536957, 0.027110841125249863, 0.019914690405130386, 0.047962278127670288, 0.019612466916441917, 0.010782618075609207, } };
const TfArray<16, int> quant8_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int32_t tensor_data9[16] = { 535, 2809, 148, 157, 358, 338, -508, -306, -409, -1221, 198, 325, 590, -108, 370, -734, };
const TfArray<1, int> tensor_dimension9 = { 1, { 16 } };
const TfArray<16, float> quant9_scale = { 16, { 0.0017283109482377768, 0.00068165338598191738, 0.0026928314473479986, 0.0012086370261386037, 0.00061460415599867702, 0.001983625115826726, 0.0021906278561800718, 0.0013534871395677328, 0.0020094092469662428, 0.0011642788304015994, 0.0009570490219630301, 0.0016446508234366775, 0.0012081038439646363, 0.0029095814097672701, 0.001189769827760756, 0.00065411621471866965, } };
const TfArray<16, int> quant9_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int8_t tensor_data10[12*208] = { 
  -52, 0, 5, -31, -12, -38, -2, -3, -19, -44, 9, -47, 10, 10, -44, -4, -27, -25, 0, -19, -43, -42, 17, -21, -43, -28, -10, -46, 10, 35, -44, 14, -17, -31, 9, -23, -36, -16, 26, -34, -80, -19, -22, -17, 10, 32, -29, 2, -25, -13, 14, -7, -23, -25, 26, -23, -80, -22, -12, -35, 8, 23, -25, 8, -34, -33, 16, -18, -42, -28, 35, -38, -120, -24, -16, -40, 22, 30, -19, 8, -28, -23, 8, -18, -50, -47, 33, -46, -66, -25, -20, -44, 5, 25, -1, 18, -37, -32, 25, 1, -32, -32, 19, -56, -65, -24, -13, -47, 19, 25, -19, 17, -50, -2, 14, -9, -43, -24, 34, -32, -85, -7, -2, -31, 17, 21, -15, 16, -47, -42, 18, 0, -50, -43, 24, -56, -56, -16, -3, -46, 16, 9, -17, 20, -40, -36, 6, -5, -45, -41, 40, -32, -57, -19, 1, -43, 29, 3, -32, 10, -64, -31, 6, 0, -36, -50, 34, -61, -47, -13, -9, -33, 26, -1, -5, 4, -44, -18, 2, -7, -32, -29, 37, -33, -50, -30, -4, -61, 27, 2, -19, 23, -62, -14, -2, -6, -22, -12, 26, -37, -26, -19, -3, -14, 4, 14, -6, 14, 
  -56, 13, 22, -39, 0, -65, -34, 5, -44, -3, -14, -23, -16, 18, -98, -65, -82, -17, 13, -54, -2, -45, -36, 9, -3, -15, -10, -31, -11, 37, -53, -52, -67, -20, 25, -30, -8, -23, -34, 14, -87, -11, -14, -28, -5, 30, -50, -65, -62, -12, 17, -16, -21, -39, -25, 8, -71, -11, -4, -67, 4, 35, -60, -70, -68, 0, 29, -25, -16, -59, -60, 14, -91, -25, 8, -76, 2, 38, -32, -43, -41, -9, 22, -18, -3, -51, -79, 8, -62, -32, 7, -72, -7, 19, -44, -88, -34, 0, 28, -9, 4, -69, -38, 19, -55, -24, 20, -80, 3, 14, -60, -72, -49, -6, 12, -17, 0, -56, -75, 1, -60, -21, 13, -64, -7, 18, -51, -91, -45, 4, 17, -12, 4, -35, -105, -1, -37, -27, 17, -76, -18, 16, -63, -98, -52, -6, 14, -12, 5, -41, -69, -5, -41, -27, 17, -94, -13, 29, -43, -54, -64, -2, 8, -5, 6, -40, -46, 0, -21, -23, 24, -89, -26, 11, -75, -63, -72, -1, 18, -11, 19, -47, -52, 9, -31, -5, 23, -88, -22, 29, -40, -58, -51, -6, 13, -4, -9, -8, -56, -32, -43, -29, -11, -45, 8, 4, -51, -53, 
  -72, -33, -24, -22, -16, 8, -41, -7, 4, -37, -31, -43, -19, -9, -6, 20, -90, -13, -19, -53, -19, 1, -15, -1, -12, -36, -15, -54, -49, 26, -13, 24, -89, -23, -12, -40, -14, 10, -29, -19, 7, -31, -18, -56, -43, 22, 1, 29, -97, -25, -14, -32, -4, 11, -39, -15, 7, -26, -26, -54, -53, 22, -7, 19, -76, -8, 2, -35, -2, 0, -18, -9, 8, -18, -57, -53, -73, 29, -22, 20, -68, -31, -9, -31, 1, 8, -3, -7, 15, -33, -21, -51, -46, 26, -10, 26, -100, -33, 9, -33, 9, 23, -17, -20, 28, -17, -30, -44, -37, 9, 3, 22, -70, -25, -18, -35, 3, 10, -17, -10, 19, -19, -25, -48, -32, 4, 10, 12, -61, -9, -19, -46, 7, 17, -47, -18, 12, -12, -19, -53, -43, -7, 8, 13, -54, -24, -23, -46, 9, 4, -32, 0, 13, -14, -29, -93, -21, -6, 1, 17, -68, -36, -18, -14, 16, 24, -35, 1, -11, -12, -24, -44, -23, -1, 5, 2, -76, -28, 12, -28, 6, 20, -5, 10, -15, -2, -8, -61, -21, 0, 14, 22, -74, -12, 1, 0, 6, -2, -52, 11, -8, -30, -8, -9, 8, -2, 9, -9, 
  -53, -11, 16, -8, -32, -68, -11, 2, -67, -52, 15, -34, 14, -17, 20, 11, -107, -8, 9, -15, -44, -63, 25, -19, -83, -32, 28, -39, 23, -9, 22, 0, -35, -5, 12, -17, -33, -17, 38, -30, -81, -15, 33, -49, 3, -23, 23, 12, -77, 2, 14, 3, -20, -25, 31, -64, -57, -18, 24, -35, 2, -22, 21, 15, -63, 2, 14, -3, -27, -29, 32, -52, -92, -24, 26, -45, -1, -12, 16, 10, -48, -14, 14, -6, -37, -53, 30, -27, -82, -14, 26, -66, 20, -8, 15, 15, -48, -10, 17, -6, -32, -36, 32, -38, -47, -27, 15, -45, 14, -5, 4, 21, -72, -25, 13, -8, -31, -35, 31, -51, -66, -14, 6, -48, 9, -13, 13, 19, -70, -22, 6, -2, -40, -39, 30, -70, -56, -17, 12, -56, 2, -17, -6, 13, -53, -14, 0, -3, -42, -37, 33, -51, -41, -17, 12, -64, 18, -1, -5, 14, -87, -10, 11, -6, -48, -43, 31, -48, -58, -29, 8, -31, 25, -16, -6, 7, -51, -14, 15, 3, -44, -24, 35, -52, -73, 4, 14, -49, 23, -21, -5, 25, -60, -7, 3, -4, -36, -32, 49, -61, -18, -24, -11, -26, -1, -28, 9, 16, 
  -62, 5, 21, -23, -20, -50, -24, 7, -55, -6, 33, -47, -34, 2, 10, -47, -95, -2, 12, -15, -26, -28, -25, 11, -27, 8, 43, -106, -16, -6, 13, -66, -83, -16, 17, -21, -5, -44, -6, 9, -46, -24, 41, -58, -11, -4, 18, -95, -82, -12, 20, -10, -11, -55, -2, 13, -37, -15, 33, -77, -13, -8, 22, -69, -67, 7, 20, -17, -9, -59, -24, 10, -39, -43, 16, -87, -7, 3, 20, -51, -58, -4, 16, -19, -5, -37, -17, 10, -39, -15, 28, -79, 1, -14, 13, -61, -55, 9, 22, -31, 13, -49, -50, 5, -56, -24, 18, -81, 9, -15, -14, -87, -73, 7, 20, -27, 4, -47, -71, 3, -64, -9, 9, -74, -5, 8, -4, -93, -49, 1, 21, -22, 3, -40, -73, 7, -53, -25, 15, -83, -27, 10, -13, -71, -50, 4, 6, -11, 20, -67, -45, 3, -44, -43, 26, -93, -13, 14, -52, -78, -56, 14, 5, -25, 12, -45, -44, 5, -41, -32, 20, -73, -30, -3, -36, -58, -66, 15, 7, -10, 14, -51, -43, 3, -38, -13, 34, -91, -37, -11, -16, -63, -39, 5, 0, -8, 8, -15, -22, -34, -35, -18, -10, -37, -12, -21, 15, -37, 
  -72, 34, -66, -5, 22, -33, -15, -37, -28, -48, -22, -61, -28, -16, -19, -11, -89, 48, -54, -15, 3, -13, -13, -32, -40, -5, -5, -10, -53, -20, 0, 3, -100, 50, -66, -1, -11, -29, -34, -28, -53, -23, -21, 0, -40, -7, -21, -21, -89, 38, -83, -19, 0, -16, -30, -26, -66, -28, -24, -31, -25, -2, -12, -15, -78, 41, -67, -16, -1, -30, -30, -32, -25, -57, -35, -12, -10, -11, -10, -11, -68, 42, -56, -14, 4, -19, -33, -29, -61, -76, -25, -27, -17, -31, -3, -11, -67, 34, -81, -25, 0, -23, -46, -22, -26, -59, -36, -34, -37, -21, -12, -25, -76, 40, -61, -20, -3, -38, -68, -28, -61, -41, -58, -20, -30, -14, -16, -36, -77, 43, -54, -34, -8, -41, -39, -25, -22, -62, -42, -41, -31, -33, -17, -22, -66, 38, -44, -33, 10, -43, -54, -22, -54, -52, -49, -27, -35, -21, -23, -6, -96, 40, -57, -21, 3, -22, -31, -29, -58, -40, -45, -9, -39, -20, -25, -24, -112, 19, -33, -10, 5, -42, -41, -20, -38, -20, -41, -40, -30, -18, -5, -25, -63, 31, -29, -6, -27, -21, -45, -26, -34, -72, -83, -16, -22, 17, -5, 0, 
  -69, -39, 19, 32, -32, 0, 4, 10, -76, 27, -22, -29, -27, -18, -34, -26, -112, -38, 22, 17, -29, 6, -8, 24, -75, 11, -50, 12, -49, -49, -10, -27, -97, -31, 16, 29, -26, -5, -2, -1, -35, -3, -41, 43, -66, -46, -8, -47, -78, -41, 11, 43, -26, 3, -29, -33, -26, 10, -13, 21, -51, -75, -11, -38, -71, -59, 21, 44, -19, 5, -4, 4, -18, 15, -33, 11, -91, -37, -18, -44, -58, -70, 5, 32, -8, -2, 7, 3, -14, 25, -50, 1, -31, -50, -27, -7, -99, -72, 24, 30, -6, 17, 2, 14, -13, 4, -67, -13, -69, -69, -17, -2, -84, -76, 16, 24, 6, 10, -15, 43, -4, 28, -47, -4, -39, -56, -21, -20, -76, -54, 8, 25, -6, 23, -12, 40, -15, 12, -72, -3, -41, -58, -39, -19, -84, -25, 1, 36, 7, 27, -19, 34, -3, 16, -57, -31, -7, -16, -37, -27, -97, -18, 12, -6, 1, 16, -24, 41, 2, 6, -37, -27, -13, -8, -40, -29, -93, -18, 8, -5, -5, 14, -18, 33, 11, 9, -41, -43, -7, -23, -38, -4, -52, -23, 1, -15, -12, 0, -86, 18, -14, -15, -37, -21, 7, -6, -16, -31, 
  -49, -9, 25, -9, -37, -2, 32, -5, -17, 20, -31, -20, -38, -27, -21, 29, -50, 31, 16, -39, -66, -37, 25, -18, -26, 37, -71, 12, -20, -56, -68, 8, -51, 15, 27, -38, -67, -13, 10, -19, -52, 28, -46, 32, -20, -46, -56, 21, -43, 17, 20, -40, -70, -36, 18, -26, -44, 33, -74, 12, -20, -32, -42, 5, -43, 1, 31, -26, -60, -59, 20, -22, -18, 31, -68, 22, -4, -46, -39, 7, -39, 8, 14, -31, -93, -39, 17, -8, -17, 31, -29, 27, -32, -31, -29, 20, -44, -7, 14, -33, -66, -24, 9, -28, -13, 18, -60, 33, -33, -17, -17, 18, -60, -8, 32, -37, -62, -28, 11, -31, -12, 22, -18, 24, -59, -34, -20, 4, -50, -14, 17, -25, -90, -5, 10, -12, -6, 18, -31, 29, -64, -16, -18, 11, -48, -2, 11, -43, -91, -8, 7, -17, -26, 11, -10, 17, -68, -35, -45, 8, -88, -6, 13, -38, -85, -21, 12, -12, -19, 24, -18, 10, -70, -24, -36, 7, -97, -6, 27, -11, -91, -37, 6, -10, -4, 10, -35, 15, -80, -36, -9, 21, -89, -2, 29, -13, -65, -13, -16, 19, -23, -42, -57, -13, -51, -30, -37, -8, 
  -71, -10, -63, 0, -13, 41, -46, -12, -91, -9, -51, -44, -22, -5, 15, -15, -48, -29, -86, 5, 2, 16, -40, -22, -9, 0, -117, -9, -1, -58, 6, -24, -55, -25, -53, -13, 19, 8, -17, -29, -30, 1, -48, -9, 3, -49, 16, -18, -83, -8, -75, -1, 11, 12, -48, -42, 1, -3, -46, -18, -5, -65, 3, -27, -51, 2, -75, -5, 27, 20, -33, -22, -20, 6, -43, 2, 2, -62, 19, -24, -39, -8, -107, -3, 18, 14, -43, -30, -4, 9, -69, -16, 13, -52, 25, -24, -43, 16, -88, -16, 19, 18, -35, -8, -11, 2, -70, 17, -3, -47, 31, -10, -49, 10, -78, -9, 15, 24, -11, -18, -30, 16, -53, 12, 6, -69, 35, -7, -55, 24, -74, 7, 16, 24, -11, -16, -25, 3, -57, 21, -6, -32, 43, -12, -57, 16, -61, -9, 3, 38, -18, -14, -23, 14, -54, 1, -8, -25, 48, -10, -59, -2, -64, 5, 14, 25, -23, -49, -28, 10, -62, 28, 5, -31, 53, -9, -46, -2, -51, -3, 9, 31, -52, -2, -19, 5, -58, -2, 9, -8, 24, -19, -92, -11, -37, -28, -17, 6, -7, -35, -20, -13, -23, -3, -9, -6, 7, -8, 
  -77, -16, -47, -65, -11, 22, -13, 11, -127, -32, -16, -57, 27, -21, -69, -29, -71, -13, -53, -40, -24, 7, -49, 44, -115, 10, -23, -61, 29, -47, -40, -14, -53, -11, -58, -24, -22, 30, -54, 37, -82, -24, -22, -58, 32, -39, -68, -21, -67, -8, -58, -60, 1, 23, -91, 28, -40, -2, -20, -120, 33, -3, -41, -41, -61, -31, -50, -46, -5, 44, -50, 32, -60, -14, 6, -46, 40, -40, -53, -55, -48, -27, -42, -53, -8, 49, -48, 19, -74, -3, 4, -55, 27, -38, -28, -73, -63, -33, -41, -18, 6, 47, -45, 29, -69, -12, -13, -35, 20, -22, -39, -55, -46, -33, -19, -31, -18, 38, -43, 22, -40, 8, -17, -46, 25, -13, -50, -68, -57, -27, -37, -22, -6, 35, -28, 26, -55, 10, -24, -59, 17, -27, -56, -51, -76, -16, -33, -23, -8, 30, -51, 25, -17, 2, -40, -59, 10, -8, -47, -24, -52, -14, -24, -18, 2, 30, -36, 17, -40, -13, -33, -45, 14, -24, -97, -21, -65, -21, -27, -16, -14, 27, -50, 15, -40, 9, -52, -57, 15, -17, -66, -19, -60, -18, -34, -3, -11, 18, -54, 8, -43, 1, -43, -59, 13, -34, -37, -86, 
  -79, 45, -65, -41, -19, -52, -13, -40, -5, -23, -12, -29, -44, -9, 11, -27, -76, 51, -45, 9, -30, -26, -23, -54, -1, 11, -18, -27, -32, -48, 1, 10, -69, 44, -37, -15, -30, -31, -40, -51, 6, 21, -39, -13, -24, -73, -6, 2, -66, 28, -34, -22, -42, -22, -56, -30, 14, 26, -24, -9, -8, -86, -4, -1, -71, 34, -33, -12, -26, -27, -46, -51, 12, 37, -52, -6, -13, -83, -11, -15, -26, 21, -18, -14, -54, -3, -71, -30, 10, 28, -31, -17, -7, -48, 2, 8, -30, 10, -11, 8, -19, -17, -44, -70, 21, 22, -31, -22, -17, -19, 7, 5, -34, 18, -26, 0, -27, -27, -45, -75, 11, 25, -24, -18, -3, -29, -3, -6, -47, 32, -21, 2, -34, -26, -38, -59, 8, 24, -42, -46, -6, -35, -1, 3, -22, 42, -25, 3, -36, -14, -68, -65, -4, 21, -22, -50, -9, -59, 4, -10, -30, 44, -51, -29, -54, -46, -40, -104, 4, 33, -41, -26, -23, -28, 2, -6, -48, 44, -17, -32, -45, -30, -57, -66, 14, 32, -26, -51, -16, -53, 17, -17, -74, 42, 22, -38, -52, -25, -28, -70, 0, -33, -30, -7, -36, -35, 4, -8, 
  -40, 2, -46, 17, 17, 7, -26, 9, -32, -23, -5, -30, -7, -5, -16, -10, 9, -14, -34, 24, 36, -7, -34, -2, -29, -43, -5, -3, -27, 7, -25, -2, -6, -7, -31, 18, 33, -9, -38, -9, -57, -22, 2, 19, -27, -11, -20, -34, -22, -11, -25, 16, 36, -19, -57, -15, -48, -25, 1, -2, -23, 15, -14, -25, -17, -16, -17, 26, 23, -19, -59, -32, -42, -31, 8, -16, -6, 13, -7, -25, 11, -23, -28, 17, 22, -13, -108, -3, -28, -19, 18, -17, -7, 6, -31, -22, 21, -12, -21, 18, 26, -8, -84, -19, -51, -37, 4, -37, -12, 12, -17, -56, -3, -13, -37, 19, 6, 0, -80, -1, -40, -40, 8, -25, -2, 0, -14, -43, 17, -10, -18, 21, 9, -7, -110, -34, -38, -32, 30, -6, 7, -15, -3, -35, 8, -12, -22, 23, -6, 7, -77, -17, -29, -30, 16, -21, 6, 7, -12, 1, 11, -3, -19, 31, 11, 8, -34, 6, -11, -35, 28, 0, -1, -26, -3, 1, 15, -15, -21, 24, 16, 17, -52, 8, 5, -12, 11, 9, 5, -7, -16, -4, -18, -22, -21, 13, -15, -3, -89, 8, -47, -39, 21, -38, -18, -30, -18, -9, 
};
const TfArray<2, int> tensor_dimension10 = { 2, { 12,208 } };
const TfArray<1, float> quant10_scale = { 1, { 0.011012191884219646, } };
const TfArray<1, int> quant10_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(16) int32_t tensor_data11[12] = { -247, 2119, 972, -1236, 78, 4993, -821, -1676, -82, 2482, -2348, -4146, };
const TfArray<1, int> tensor_dimension11 = { 1, { 12 } };
const TfArray<1, float> quant11_scale = { 1, { 0.00042312740697525442, } };
const TfArray<1, int> quant11_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,50,13 } };
const TfArray<1, float> quant12_scale = { 1, { 0.050557747483253479, } };
const TfArray<1, int> quant12_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,50,32 } };
const TfArray<1, float> quant13_scale = { 1, { 0.060663953423500061, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,50,1,32 } };
const TfArray<1, float> quant14_scale = { 1, { 0.060663953423500061, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,25,1,32 } };
const TfArray<1, float> quant15_scale = { 1, { 0.060663953423500061, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,25,32 } };
const TfArray<1, float> quant16_scale = { 1, { 0.060663953423500061, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,25,16 } };
const TfArray<1, float> quant17_scale = { 1, { 0.038423541933298111, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,25,1,16 } };
const TfArray<1, float> quant18_scale = { 1, { 0.038423541933298111, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,13,1,16 } };
const TfArray<1, float> quant19_scale = { 1, { 0.038423541933298111, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,208 } };
const TfArray<1, float> quant20_scale = { 1, { 0.038423541933298111, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,12 } };
const TfArray<1, float> quant21_scale = { 1, { 0.16613583266735077, } };
const TfArray<1, int> quant21_zero = { 1, { 58 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,12 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 12,6,7 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 13,2 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 15,3 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 16,8,9 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 17,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,5 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,10,11 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 656, (TfLiteIntArray*)&tensor_dimension0, 650, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 1248, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 128, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 1536, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 2496, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 48, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 650, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1600, (TfLiteIntArray*)&tensor_dimension13, 1600, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 1600, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1600, (TfLiteIntArray*)&tensor_dimension15, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 800, (TfLiteIntArray*)&tensor_dimension17, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 400, (TfLiteIntArray*)&tensor_dimension19, 208, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension20, 208, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 208, (TfLiteIntArray*)&tensor_dimension21, 12, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension22, 12, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant22))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs10, (TfLiteIntArray*)&outputs10, const_cast<void*>(static_cast<const void*>(&opdata10)), OP_SOFTMAX, },
};
static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else {
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 11; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 11; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  22, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
